{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40abdaae",
   "metadata": {},
   "source": [
    "# CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cade580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2773edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "  def __init__(self):\n",
    "    self.img_rows = 128\n",
    "    self.img_cols = 128\n",
    "    self.channels = 3\n",
    "    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "    self.dataset_name = 'apple2orange'\n",
    "    self.data_loader = DataLoader(datase_name=self.dataset_name,\n",
    "                                  img_res = (self.img_rows, self.img_cols))\n",
    "    patch = int(self.img_rows / 2**4)\n",
    "    self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "    self.gf = 32\n",
    "    self.df = 64\n",
    "\n",
    "    self.lambda_cycle = 10.0\n",
    "    self.lambda_id = 0.9 * self.lambda_cycle\n",
    "\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "    self.d_A = self.build_discriminator()\n",
    "    self.d_B = self.build_discriminator()\n",
    "    self.d_A.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    self.d_B.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    self.g_AB = self.build_generator()\n",
    "    self.g_BA = self.build_generator()\n",
    "\n",
    "    img_A = Input(shape=self.img_shape)\n",
    "    img_B = Input(shape=self.img_shape)\n",
    "\n",
    "    fake_B = self.g_AB(img_A)\n",
    "    fake_A = self.g_BA(img_B)\n",
    "    reconstr_A = self.g_BA(fake_B)\n",
    "    reconstr_B = self.g_AB(fake_A)\n",
    "    img_A_id = self.g_BA(img_A)\n",
    "    img_B_id = self.g_AB(img_B)\n",
    "\n",
    "    self.d_A.trainable = False\n",
    "    self.d_B.trainable = False\n",
    "\n",
    "    valid_A = self.d_A(fake_A)\n",
    "    valid_B = self.d_B(fake_B)\n",
    "\n",
    "    self.combined = Model(inputs=-[img_A, img_B], outputs=[valid_A, valid_B,\n",
    "                                                           reconstr_A, reconstr_B,\n",
    "                                                           img_A_id, img_B_id])\n",
    "    self.combined.compile(loss=['mse','mse',\n",
    "                                'mae','mae'\n",
    "                                'mae','mae'],\n",
    "                          loss_weights=[1, 1,\n",
    "                                        self.lambda_cycle, self.lambda_cycle,\n",
    "                                        self.lambda_id, self.lambda_id],\n",
    "                          optimizer=optimizer)\n",
    "  def build_generator(self):\n",
    "    def conv2d(layer_input, filters, f_size=4, normalization=True):\n",
    "      d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "      d = LeakyReLU(alpha=0.2)(d)\n",
    "      if normalization:\n",
    "        d = InstanceNormalization()(d)\n",
    "      return d\n",
    "\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "      u = UpSampling2D(size=2)(layer_input)\n",
    "      u = Conv2D(filters, kernel_size=f_size, strides=1, paddinng='same', activation='relu')(u)\n",
    "      if dropout_rate:\n",
    "        u = Dropout(dropout_rate)\n",
    "      u = InstanceNormalization()(u)\n",
    "      u = Concatenate([u, skip_input])\n",
    "      return u\n",
    "\n",
    "    d0 = Input(shape=self.img_shape)\n",
    "\n",
    "    d1 = self.conv2d(d0, self.gf)\n",
    "    d2 = self.conv2d(d1, self.gf * 2)\n",
    "    d3 = self.conv2d(d2, self.gf * 4)\n",
    "    d4 = self.conv2d(d3, self.gf * 8)\n",
    "    u1 = self.deconv2d(d4, d3, self.gf * 4)\n",
    "    u2 = self.deconv2d(u1, d2, self.gf * 2)\n",
    "    u3 = self.deconv2d(u2, d1, self.gf)\n",
    "\n",
    "    u4 = UpSampling2D(size=2)(u3)\n",
    "    output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activaiton='tanh')(u4)\n",
    "\n",
    "    return Model(d0, output_img)\n",
    "\n",
    "  def build_discriminator(self):\n",
    "    img = Input(shape=self.img_shape)\\\n",
    "\n",
    "    d1 = self.conv2d(img, self.df, normalization=False)\n",
    "    d2 = self.conv2d(d1, self.df * 2)\n",
    "    d3 = self.conv2d(d2, self.df * 4)\n",
    "    d4 = self.conv2d(d3, self.df * 8)\n",
    "\n",
    "    validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "    return Model(img, validity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
