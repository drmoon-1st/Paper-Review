{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0fd62c",
   "metadata": {},
   "source": [
    "# StyleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b85377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4c0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, gain=2**(0.5), use_wscale=False, lrmul=1, bias=True):\n",
    "        super().__init__()\n",
    "        he_std = gain * input_size**(-0.5)\n",
    "        if use_wscale:\n",
    "            init_std = 1.0 / lrmul\n",
    "            self.w_mul = he_std * lrmul\n",
    "        else:\n",
    "            init_std = he_std / lrmul\n",
    "            self.w_mul = lrmul\n",
    "        self.weight = torch.nn.Parameter(torch.randn(output_size, input_size) * init_std)\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.zeros(output_size))\n",
    "            self.b_mul = lrmul\n",
    "        else:\n",
    "            self.bias = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bias = self.bias\n",
    "        if bias is not None:\n",
    "            bias = bias * self.b_mul\n",
    "        return F.linear(x, self.weight * self.w_mul, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a036ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv2d(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size, gain=2**(0.5), use_wscale=False, lrmul=1,\n",
    "                bias=True, intermediate=None, upscale=False):\n",
    "        super().__init__()\n",
    "        if upscale:\n",
    "            self.upscale = Upscale2d()\n",
    "        else:\n",
    "            self.upscale = None\n",
    "        he_std = gain * (input_channels * kernel_size ** 2) ** (-0.5)\n",
    "        self.kernel_size = kernel_size\n",
    "        if use_wscale:\n",
    "            init_std = 1.0 / lrmul\n",
    "            self.w_mul = he_std * lrmul\n",
    "        else:\n",
    "            init_std = he_std / lrmul\n",
    "            self.w_mul = lrmul\n",
    "        self.weight = torch.nn.Parameter(torch.randn(output_channels, input_channels, kernel_size, kernel_size) * init_std)\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.zeros(output_channels))\n",
    "            self.b_mul = lrmul\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.intermediate = intermediate\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bias = self.bias\n",
    "        if bias is not None:\n",
    "            bias = bias * self.b_mul\n",
    "        \n",
    "        have_convolution = False\n",
    "        if self.upscale is not None and min(x.shape[2:]) * 2 >= 128:\n",
    "            w = self.weight * self.w_mul\n",
    "            w = w.permute(1, 0, 2, 3)\n",
    "            w = F.pad(w, (1, 1, 1, 1))\n",
    "            w = w[:, :, 1:, 1:] + w[:, :, :-1, 1:] + w[:, :, 1:, :-1] + w[:, :, :-1, :-1]\n",
    "            x = F.conv_transpose2d(x, w, stride=2, padding=(w.size(-1)-1)//2)\n",
    "            have_convolution = True\n",
    "        elif self.upscale is not None:\n",
    "            x = self.upscale(x)\n",
    "        \n",
    "        if not have_convolution and self.intermediate is None:\n",
    "            return F.conv2d(x, self.weight * self.w_mul, bias, padding=self.kernel_size//2)\n",
    "        elif not have_convolution:\n",
    "            x = F.conv2d(x, self.weigt * sle.w_mul, None, padding=self.kernel_size//2)\n",
    "            \n",
    "        if self.intermediate is not None:\n",
    "            x = self.intermediate(x)\n",
    "        if bias is not None:\n",
    "            x = x + bias.view(1, -1, 1, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60aa901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseLayer(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.zeros(channels))\n",
    "        self.noise = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if noise is None and self.noise is None:\n",
    "            noise = torch.randn(x.size(0), 1, x.size(2), x.size(3), device=x.device, dtype=x.dtype)\n",
    "        elif noise is None:\n",
    "            noise = self.noise\n",
    "        x = x + self.weight.view(1, -1, 1, 1) * noise\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39b566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleMod(nn.Module):\n",
    "    def __init__(self,latent_size, channels, use_wscale):\n",
    "        super(StyleMod, self).__init__()\n",
    "        self.lin = MyLinear(latent_size, channels * 2, gain=1.0, use_wscale=use_wscale)\n",
    "        \n",
    "    def forward(self, x, latent):\n",
    "        style = self.lin(latent)\n",
    "        shape = [-1, 2, x.size(1)] + (x.dim() - 2) * [1]\n",
    "        style= style.view(shape)\n",
    "        x = x * (style[:, 0] + 1.) + style[:, 1]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76146b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNormLayer(nn.Module):\n",
    "    def __init__(self, epsilon=1e-8):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * torch.rsqrt(torch.mean(x**2, dim=1, keepdim=True) + self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c17e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurLayer(nn.Module):\n",
    "    def __init__(self, kernel=[1, 2, 1], normalize=True, flip=False, stride=1):\n",
    "        super(BlurLayer, self).__init__()\n",
    "        kernel = [1, 2, 1]\n",
    "        kernel = torch.tensor(kernel,dtype=torch.float32)\n",
    "        kernel = kernel[:, None] * kernel[None, :]\n",
    "        kernel = kernel[None, None]\n",
    "        if normalize:\n",
    "            kernel = kernel / kernel.sum()\n",
    "        if flip:\n",
    "            kernel = kernel[:, :, ::-1, ::-1]\n",
    "        self.register_buffer('kernel', kernel)\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        kernel = self.kernel.expand(x.size(1), -1, -1, -1)\n",
    "        x = F.conv2d(\n",
    "            x, kernel,\n",
    "            stride=self.stride,\n",
    "            padding=int((self.kernel.size(2)-1)/2),\n",
    "            groups=x.size(1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce6b6986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale2d(x, factor=2, gain=1):\n",
    "    assert x.dim() == 4\n",
    "    if gain != 1:\n",
    "        x = x* gain\n",
    "    if factor != 1:\n",
    "        shape = x.shape\n",
    "        x = x.view(shape[0], shape[1], shape[2], 1, shape[3], 1).expand(-1, -1, -1, factor, -1, factor)\n",
    "        x = x.contiguous().view(shape[0], shape[1], factor * shape[2], factor * shape[3])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca202f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upscale2d(nn.Module):\n",
    "    def __init__(self, factor=2, gain=1):\n",
    "        super().__init__()\n",
    "        assert isinstance(factor, int) and factor >= 1\n",
    "        self.gain = gain\n",
    "        self.factor = factor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return upscale2d(x, factor=self.factor, gain=self.gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c017a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G_mapping(nn.Sequential):\n",
    "    def __init__(self, nonlinearity='lrelu', use_wscale=True):\n",
    "        act, gain = {'relu': (torch.relu, np.sqrt(2)),\n",
    "                     'lrelu': (nn.LeakyReLU(negative_slope=0.2), np.sqrt(2))}[nonlinearity]\n",
    "        \n",
    "        layers = [\n",
    "            ('pixel_norm', PixelNormLayer()),\n",
    "            ('dense0', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n",
    "            ('dense0_act', act),\n",
    "            ('dense1', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n",
    "            ('dense1_act', act),\n",
    "            ('dense2', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n",
    "            ('dense2_act', act),\n",
    "            ('dense3', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n",
    "            ('dense3_act', act),\n",
    "            ('dense4', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n",
    "            ('dense4_act', act),\n",
    "            ('dense5', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n",
    "            ('dense5_act', act),\n",
    "            ('dense6', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n",
    "            ('dense6_act', act),\n",
    "            ('dense7', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n",
    "            ('dense7_act', act)\n",
    "        ]\n",
    "        super().__init__(OrderedDict(layers))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = super().forward(x)\n",
    "        x = x.unsqueeze(1).expand(-1, 18, -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea73ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Truncation(nn.Module):\n",
    "    def __init__(self, avg_latent, max_layer=8, threshold=0.7):\n",
    "        super().__init__()\n",
    "        self.max_layer = max_layer\n",
    "        self.threshold = threshold\n",
    "        self.register_buffer('avg_latent', avg_latent)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert x.dim() == 3\n",
    "        interp = torch.lerp(self.avg_latent, x, self.threshold)\n",
    "        do_trunc = (torch.arange(x.size(1)) < self.max_layer).view(1, -1, 1)\n",
    "        return torch.where(do_trunc, interp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88738c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerEpilogue(nn.Module):\n",
    "    def __init__(self, channels, dlatent_size, use_wscale, use_noise, use_pixel_norm, use_instance_norm,\n",
    "                use_styles, activation_layer):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        if use_noise:\n",
    "            layers.append(('noise', NoiseLayer(channels)))\n",
    "        layers.append(('activation', activation_layer))\n",
    "        if use_pixel_norm:\n",
    "            layers.append(('instance_norm', nn.InstanceNorm2d(channels)))\n",
    "        self.top_epi = nn.Sequential(OrderedDict(layers))\n",
    "        if use_styles:\n",
    "            self.style_mod = StyleMod(dlatent_size, channels, use_wscale=use_wscale)\n",
    "        else:\n",
    "            self.style_mod = None\n",
    "            \n",
    "    def forward(self, x, dlatent_in_slice=None):\n",
    "        x = self.top_epi(x)\n",
    "        if self.style_mod is not None:\n",
    "            x = self.style_mod(x, dlatent_in_slice)\n",
    "        else:\n",
    "            assert dlatent_in_slice is None\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf8e8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputBlock(nn.Module):\n",
    "    def __init__(self, nf, dlatent_size, const_input_layer, gain, use_wscale, use_noise, use_pixel_norm,\n",
    "                use_instance_norm, use_styles, activation_layer):\n",
    "        super().__init__()\n",
    "        self.const_input_layer = const_input_layer\n",
    "        self.nf = nf\n",
    "        if self.const_input_layer:\n",
    "            self.const = nn.Parameter(torch.ones(1, nf, 4, 4))\n",
    "            self.bias = nn.Parameter(torch.ones(nf))\n",
    "        else:\n",
    "            self.dense = MyLinear(dlatent_size, nf*16, gain=gain/4, use_wscale=use_wscale)\n",
    "        self.epi1 = LayerEpilogue(nf, dlatent_size, use_wscale, use_noise, use_pixel_norm, use_instance_norm,\n",
    "                                 use_styles, activation_layer)\n",
    "        self.conv = MyConv2d(nf, nf, 3, gain=gain, use_wscale=use_wscale)\n",
    "        self.epi2 = LayerEpilogue(nf, dlatent_size, use_wscale, use_noise, use_pixel_norm,\n",
    "                                 use_instance_norm, use_styles, activation_layer)\n",
    "        \n",
    "    def forward(self, dlatent_in_range):\n",
    "        batch_size = dlatnet_in_range.size(0)\n",
    "        if self.const_input_layer:\n",
    "            x = self.const.expand(batch_size, -1, -1, -1)\n",
    "            x  = x + self.bias.view(1, -1, 1, 1)\n",
    "        else:\n",
    "            x = self.dense(dlayent_in_range[:, 0]).view(batch_size, self.nf, 4, 4)\n",
    "        x = self.epi(x, dlatent_in_range[:, 0])\n",
    "        x = conv(x)\n",
    "        x = self.epi2(x, dlatent_in_range[:, 1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7442209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSynthesisBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, blur_filter, dlatent_size, gain,\n",
    "                use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, activation_layer):\n",
    "        super().__init__()\n",
    "        if blur_filter:\n",
    "            blur = BlurLayer(blur_filter)\n",
    "        else:\n",
    "            blur = None\n",
    "        self.conv0_up = MyConv2d(in_channels, out_channels, kernel_size=3, gain=gain,\n",
    "                                use_wscale=use_wscale, intermediate=blur, upscale=True)\n",
    "        self.epi1 = LayerEpilogue(out_channels, dlatent_size, use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, activation_layer)\n",
    "        self.conv1 = MyConv2d(out_channels, out_channels, kernel_size=3, gain=gain, use_wscale=use_wscale)\n",
    "        self.epi2 = LayerEpilogue(out_channels, dlatent_size, use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, activation_layer)\n",
    "            \n",
    "    def forward(self, x, dlatents_in_range):\n",
    "        x = self.conv0_up(x)\n",
    "        x = self.epi1(x, dlatents_in_range[:, 0])\n",
    "        x = self.conv1(x)\n",
    "        x = self.epi2(x, dlatents_in_range[:, 1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7af1c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G_synthesis(nn.Module):\n",
    "    def __init__(self,\n",
    "        dlatent_size        = 512,\n",
    "        num_channels        = 3,\n",
    "        resolution          = 1024,\n",
    "        fmap_base           = 8192,\n",
    "        fmap_decay          = 1.0,\n",
    "        fmap_max            = 512,\n",
    "        use_styles          = True,\n",
    "        const_input_layer   = True,\n",
    "        use_noise           = True,\n",
    "        randomize_noise     = True,\n",
    "        nonlinearity        = 'lrelu',\n",
    "        use_wscale          = True,\n",
    "        use_pixel_norm      = False,\n",
    "        use_instance_norm   = True,\n",
    "        dtype               = torch.float32,\n",
    "        blur_filter         = [1,2,1]\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        def nf(stage):\n",
    "            return min(int(fmap_base / (2.0 **(stage*fmap_decay))), fmap_max)\n",
    "        \n",
    "        self.dlatent_size = dlatent_size\n",
    "        resolution_log2 = int(np.log2(resolution))\n",
    "        assert resolution == 2 ** resolution_log2 and resolution >= 4\n",
    "        \n",
    "        act, gain = {'relu': (torch.relu, np.sqrt(2)),\n",
    "                     'lrelu': (nn.LeakyReLU(negative_slope=0.2), np.sqrt(2))}[nonlinearity]\n",
    "        num_layers = resolution_log2 * 2 - 2\n",
    "        num_styles = num_layers if use_styles else 1\n",
    "        torgbs = []\n",
    "        blocks = []\n",
    "        for res in range(2, resolution_log2+1):\n",
    "            channels = nf(res-1)\n",
    "            name = '{s}x{s}'.format(s=2**res)\n",
    "            if res == 2:\n",
    "                blocks.append((name,\n",
    "                               InputBlock(channels, dlatent_size, const_input_layer, gain, use_wscale,\n",
    "                                      use_noise, use_pixel_norm, use_instance_norm, use_styles, act)))\n",
    "            else:\n",
    "                blocks.append((name,\n",
    "                               GSynthesisBlock(last_channels, channels, blur_filter, dlatent_size, gain, use_wscale, \n",
    "                                               use_noise, use_pixel_norm, use_instance_norm, use_styles, act)))\n",
    "            last_channels = channels\n",
    "        self.torgb = MyConv2d(channels, num_channels, 1, gain=1, use_wscale=use_wscale)\n",
    "        self.blocks = nn.ModuleDict(OrderedDict(blocks))\n",
    "        \n",
    "    def forward(self, dlatent_in):\n",
    "        batch_size = dlatent_in.size(0)\n",
    "        for i, m in enumerate(self.blocks.values()):\n",
    "            if i == 0:\n",
    "                x = m(dlatent_in[:, 2*i:2*i+2])\n",
    "            else:\n",
    "                x = m(x, dlatent_in[:, 2*i:2*i+2])\n",
    "        rgb = self.torgb(x)\n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd6b6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_all = nn.Sequential(OrderedDict([\n",
    "    ('g_mapping', G_mapping()),\n",
    "    ('g_synthesis', G_synthesis())    \n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951102d2",
   "metadata": {},
   "source": [
    "code from : https://github.com/lernapparat/lernapparat/blob/master/style_gan/pytorch_style_gan.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
